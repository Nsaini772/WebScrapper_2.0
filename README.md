**#Webscrapper_upgrade in Upgraded_roject branch**
In this project I used OOPS with python
1. It contains __pychache__ directory is a Python-specific directory used for caching compiled bytecode files (.pyc) to improve the performance of importing Python modules. It is automatically generated by Python's interpreter to store these bytecode files for modules in order to speed up the execution of Python code.
2. To run the script:
command :- **python3 /Users/swastik/Downloads/CS325/Project3/run.py https://old.reddit.com/r/funny/comments/16ke3e5/can_anyone_verify_this_stuff/**
3. Errors: Sometimes this will give error or response.text not working, I checked that this error is not with code with is due to the old version of the website we are using. To overcome that just clear the terminal and try multiple times, this is due to url or website only
4. In this Upgraded version of the project:
    1. run.py :- This script import all the other modules and work collaboratively
    2. data_fetcher.py :- The primary purpose of this script is to fetch HTML content from a URL using the requests library and save that content to a specified output file. The         HTML content can then be processed or analyzed further if needed.
    3. html_parser.py :- The primary purpose of this script is to extract user comments from the HTML content of a given URL. The extracted comments are returned as a single             string, where each comment is separated by a newline character. This script can be used in conjunction with the DataFetcher class from your previous question to fetch and          parse HTML content from a URL and extract user comments.
    4. file_manager.py :- The primary purpose of this script is to provide utility methods for creating directories and saving text data to files. It can be used in various              scenarios within a Python program to manage file and directory operations.
  
5. Also used conda environment named proj3, so also yaml is included in this repository.

This script is using the url and giving the two output files i.e. raw_data.txt and processed_data.txt files.
raw_data.txt :- contains the dump data of the website
processed_data.txt :- contains only the user comments excluding the html tags






# WebScrapper_2.0

input file or dump file from WebScrapper (previous code):- output_file1.txt
refined output file form the WebScrapper_2.0 :- output_file2.txt

yaml file contains the details of all the libraries installed like requests and beautifulsoup4

to run this script:- python3 Project2.py output_file1.txt output_file2.txt
in general:- python3 your_python_script.py input.txt output.txt

In this project I tried to remove the tags fromt eh dump file and stored the user comments as a output file. During this I inspect the website and figure out which tag and class or id contains the user comment data then used that details with soup to extract data. 
I used soup.find_all() method. It's a method provided by the BeautifulSoup object to search and find all instances of a specific HTML element or tag within the parsed HTML content.
And then getting the data from the class "usertext-body".
